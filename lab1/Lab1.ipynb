{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df3012aa-b0b5-443c-ade5-10832d53fd19",
   "metadata": {},
   "source": [
    "(a) Algorithm implementation:\n",
    "Implement the above hybrid algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86970899-0cbb-4dd7-a2fc-df4fed9ec868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "comparison_counter = 0\n",
    "\n",
    "# Insertion Sort Algorithm\n",
    "def insertion_sort(arr, left, right):\n",
    "    global comparison_counter\n",
    "    for i in range(left + 1, right + 1):\n",
    "        temp = arr[i]\n",
    "        j = i - 1\n",
    "        while j >= left and arr[j] > temp:\n",
    "            comparison_counter += 1\n",
    "            arr[j + 1] = arr[j]\n",
    "            j -= 1\n",
    "        arr[j + 1] = temp\n",
    "\n",
    "# Merge Function\n",
    "def merge(arr, left, mid, right):\n",
    "    global comparison_counter\n",
    "    left_arr = arr[left : mid + 1]\n",
    "    right_arr = arr[mid + 1 : right + 1]\n",
    "\n",
    "    i, j, k = 0, 0, left \n",
    "\n",
    "    l1 = len(left_arr)\n",
    "    l2 = len(right_arr)\n",
    "    \n",
    "    while i < l1 and j < l2:\n",
    "        comparison_counter += 1\n",
    "        if left_arr[i] <= right_arr[j]:\n",
    "            arr[k] = left_arr[i]\n",
    "            i += 1\n",
    "        else:\n",
    "            arr[k] = right_arr[j]\n",
    "            j += 1\n",
    "        k += 1\n",
    "\n",
    "    while i < l1:\n",
    "        arr[k] = left_arr[i]\n",
    "        i += 1\n",
    "        k += 1\n",
    "\n",
    "    while j < l2:\n",
    "        arr[k] = right_arr[j]\n",
    "        j += 1\n",
    "        k += 1\n",
    "\n",
    "# Merge Sort Algorithm\n",
    "def merge_sort(arr, left, right):\n",
    "    global comparison_counter\n",
    "    if (left >= right):\n",
    "        return\n",
    "    mid = (left + right) // 2\n",
    "    merge_sort(arr, left, mid)\n",
    "    merge_sort(arr, mid + 1, right)\n",
    "    merge (arr, left, mid, right)\n",
    "\n",
    "# Hybrid Sort Algorithm\n",
    "def hybrid_sort(arr, left, right, S):\n",
    "    global comparison_counter\n",
    "    if right - left <= S:\n",
    "        insertion_sort(arr, left, right)\n",
    "    else:\n",
    "        mid = (left + right) // 2\n",
    "        hybrid_sort(arr, left, mid, S)\n",
    "        hybrid_sort(arr, mid + 1, right, S)\n",
    "        merge(arr, left, mid, right)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb273736-71ab-46b4-a35f-b950e3f96d2e",
   "metadata": {},
   "source": [
    "(b) Generate input data:\n",
    "Generate arrays of increasing sizes, in a range from 1,000 to 10 million. For each of the sizes, generate a random dataset of integers in the range of [1, ..., x], where x is the largest number you allow for your datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a9b6505-c95b-4202-8bfc-7ed132e387a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to generate dictionary with key being size and value being the list of random integers\n",
    "def generate_data(start = 1000, end = 10000000, step = 10, seed = 0):\n",
    "    np.random.seed(seed) # fix the seed for consistency\n",
    "    dataset = {}\n",
    "    while start <= end:\n",
    "        dataset[start] = np.random.randint(1, start + 1, start)\n",
    "        start *= step\n",
    "    return dataset\n",
    "\n",
    "dataset = generate_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a52e3e-f06e-417b-a761-c21f89c1b405",
   "metadata": {},
   "source": [
    "(c) Analyze time complexity:\n",
    "Run your program of the hybrid algorithm on the datasets generated in Step (b). Record the number of key comparisons performed in each case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a3ac33-b64c-4b31-b834-c2eb95e64aed",
   "metadata": {},
   "source": [
    "With the value of S fixed, plot the number of key comparisons over different sizes of the input list n. Compare your empirical results with your theoretical analysis of the time complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0122a1d-2cac-45c7-90b6-a31868944432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 1000, Number of comparisons: 5318\n",
      "Size: 10000, Number of comparisons: 78602\n",
      "Size: 100000, Number of comparisons: 926417\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store results for plotting\n",
    "comparison_results = {}\n",
    "\n",
    "# Run the hybrid sort algo multiple times, storing the number of comparisons in an array\n",
    "for size, arr in dataset.items():\n",
    "    arr_copy = arr.copy()  \n",
    "\n",
    "    hybrid_sort(arr_copy, 0, len(arr_copy) - 1, S=10)  \n",
    "\n",
    "    comparison_results[size] = comparison_counter\n",
    "\n",
    "    print(f\"Size: {size}, Number of comparisons: {comparison_counter}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497e6dcc-11e0-4c9f-b3ac-2918bd0fc8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = list(comparison_results.keys())\n",
    "comparison_counts = list(comparison_results.values())\n",
    "\n",
    "# Plot Dataset Size vs Number of Comparisons\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(sizes, comparison_counts, linestyle='-', color='b', label=\"Number of Comparisons\")\n",
    "plt.xlabel(\"Dataset Size\")\n",
    "plt.ylabel(\"Number of Comparisons\")\n",
    "plt.title(\"Hybrid Sort: Dataset Size vs Number of Comparisons\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d53ce2-0cbe-4364-8eac-c7c6e6cb3a9b",
   "metadata": {},
   "source": [
    "With the input size n fixed, plot the number of key comparisons over different values of S. Compare your empirical results with your theoretical analysis of the time complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93fe1b8-a060-4977-b69a-f8d43b798ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use fixed dataset and vary S, extracting the sort time and comparison count \n",
    "results = {}\n",
    "\n",
    "for S in range (2, 175):\n",
    "    # Reset comparison_counter\n",
    "    comparison_counter = 0\n",
    "    copied_data = dataset[10000].copy()\n",
    "    start_time = time.time()\n",
    "    hybrid_sort(copied_data, 0, len(copied_data) - 1, S)\n",
    "    end_time = time.time()\n",
    "    sort_time = end_time - start_time\n",
    "    results[S] = [sort_time, comparison_counter]\n",
    "\n",
    "# Extract S values, sort times, and comparison counts from results dictionary\n",
    "S_values = list(results.keys())\n",
    "sort_times = [results[S][0] for S in S_values]  # Extract sort times\n",
    "comparison_counts = [results[S][1] for S in S_values]  # Extract comparison counts\n",
    "\n",
    "# Plotting S vs Sort Time\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(S_values, sort_times, linestyle='-', color='b', label=\"Sort Time\")\n",
    "plt.xlabel(\"S\")\n",
    "plt.ylabel(\"Sort Time (s)\")\n",
    "plt.title(\"Hybrid Sort: S vs Sort Time\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plotting S vs Comparison Count\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(S_values, comparison_counts, linestyle='-', color='r', label=\"Comparison Count\")\n",
    "plt.xlabel(\"S\")\n",
    "plt.ylabel(\"Comparison Count\")\n",
    "plt.title(\"Hybrid Sort: S vs Comparison Count\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7f5928-f2ef-473f-8b0e-c2b7943cba7c",
   "metadata": {},
   "source": [
    "Using different sizes of input datasets, study how to determine an optimal value of S for the best performance of this hybrid algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b2fd07-ef78-4360-95e1-eaf780558293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to measure sorting performance for different S values\n",
    "def measure_sort_performance(num_trials=100):\n",
    "    sizes = list(range(1, 26))  # Test S values from 1 to 25\n",
    "    merge_comparisons = []\n",
    "    insertion_comparisons = []\n",
    "    \n",
    "    merge_times = []\n",
    "    insertion_times = []\n",
    "    \n",
    "    for n in sizes:\n",
    "        merge_comparisons_total = 0\n",
    "        insertion_comparisons_total = 0\n",
    "        merge_time_total = 0\n",
    "        insertion_time_total = 0\n",
    "\n",
    "        for _ in range(num_trials):  # Run multiple trials for averaging\n",
    "            arr = np.random.randint(1, n + 1, n)  # Generate small random array\n",
    "\n",
    "            # Measure Merge Sort comparisons and runtime\n",
    "            arr_copy = arr.copy()\n",
    "            global comparison_counter\n",
    "            comparison_counter = 0\n",
    "            start_time = time.time()\n",
    "            merge_sort(arr_copy, 0, len(arr_copy) - 1)\n",
    "            merge_time_total += time.time() - start_time\n",
    "            merge_comparisons_total += comparison_counter\n",
    "\n",
    "            # Measure Insertion Sort comparisons and runtime\n",
    "            arr_copy = arr.copy()\n",
    "            comparison_counter = 0\n",
    "            start_time = time.time()\n",
    "            insertion_sort(arr_copy, 0, len(arr_copy) - 1)\n",
    "            insertion_time_total += time.time() - start_time\n",
    "            insertion_comparisons_total += comparison_counter\n",
    "\n",
    "        # Compute average key comparisons and runtime\n",
    "        merge_comparisons.append(merge_comparisons_total / num_trials)\n",
    "        insertion_comparisons.append(insertion_comparisons_total / num_trials)\n",
    "        merge_times.append(merge_time_total / num_trials)\n",
    "        insertion_times.append(insertion_time_total / num_trials)\n",
    "\n",
    "    # Plot Key Comparisons (Merge Sort vs Insertion Sort)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(sizes, merge_comparisons, label=\"Merge Sort (Comparisons)\", marker=\"o\", linestyle='--', color='blue')\n",
    "    plt.plot(sizes, insertion_comparisons, label=\"Insertion Sort (Comparisons)\", marker=\"s\", linestyle='-.', color='red')\n",
    "    plt.xlabel(\"Array Size (S)\")\n",
    "    plt.ylabel(\"Average Key Comparisons\")\n",
    "    plt.title(\"Merge Sort vs Insertion Sort - Key Comparisons\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Runtime (Merge Sort vs Insertion Sort)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(sizes, merge_times, label=\"Merge Sort (Time)\", marker=\"o\", linestyle='--', color='blue')\n",
    "    plt.plot(sizes, insertion_times, label=\"Insertion Sort (Time)\", marker=\"s\", linestyle='-.', color='red')\n",
    "    plt.xlabel(\"Array Size (S)\")\n",
    "    plt.ylabel(\"Average Runtime (s)\")\n",
    "    plt.title(\"Merge Sort vs Insertion Sort - Runtime\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Run performance measurement\n",
    "measure_sort_performance(num_trials=100)  # Run 100 trials per size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abece214-f7e1-4b38-b917-a3ddcdefa3bb",
   "metadata": {},
   "source": [
    "(d) Compare with original Mergesort:\n",
    "Implement the original version of Mergesort (as learnt in lecture). Compare its performance against the above hybrid algorithm in terms of the number of key comparisons and CPU times on the dataset with 10 million integers. You can use the optimal value of S obtained in (c) for this task.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25d42810-04e7-4e54-84c0-e585c482efa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid sort takes 25.537683963775635s of runtime and makes 100322625 comparisons to run\n",
      "Merge sort takes 31.73897695541382s of runtime and makes 118788160 comparisons to run \n"
     ]
    }
   ],
   "source": [
    "# Standard Mergesort Algorithm\n",
    "optimal_s = 9 # need to replace this with the optimal s\n",
    "\n",
    "copied_array = dataset[10000000].copy()\n",
    "# Hybrid Sort Execution\n",
    "start_time = time.time()\n",
    "hybrid_sort(arr_copy, 0, len(arr_copy) - 1, optimal_s) \n",
    "end_time = time.time()\n",
    "hybrid_time = end_time - start_time\n",
    "hybrid_comparisons = comparison_counter\n",
    "\n",
    "# Standard Mergesort Execution\n",
    "comparison_counter = 0\n",
    "copied_array = dataset[10000000].copy()\n",
    "start_time = time.time()\n",
    "merge_sort(arr_copy, 0, len(arr_copy) - 1)\n",
    "end_time = time.time()\n",
    "merge_time = end_time - start_time\n",
    "merge_comparisons = comparison_counter\n",
    "\n",
    "\n",
    "print(f\"Hybrid sort takes {hybrid_time}s of runtime and makes {hybrid_comparisons} comparisons to run\")\n",
    "print(f\"Merge sort takes {merge_time}s of runtime and makes {merge_comparisons} comparisons to run \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
